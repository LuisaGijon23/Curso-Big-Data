{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1h8GFvOwJkW++EC5ESXlv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Modelos de Regresión\n","\n","------------------------------------------------------\n","\n","\n","### Data Science and Machine Learning\n","\n","#### Abril 2023\n","\n","**Aurora Cobo Aguilera**\n","\n","**The Valley**\n","\n","------------------------------------------------------"],"metadata":{"id":"SQjVdWtZFtVr"}},{"cell_type":"markdown","source":["## 1. Regresión *k*-nearest neighbors (*k*NN)\n","\n","En este notebook describiremos la siguiente tarea de regresión que vamos a estudiar. Se trata de la regresión *k*NN, un modelo no paramétrico."],"metadata":{"id":"Eu2rnzBDFq2Y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fdl6m-gnFogY"},"outputs":[],"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pylab\n","import scipy.io       \n","import pandas as pd   \n","\n","%matplotlib inline \n","pylab.rcParams['figure.figsize'] = 9, 6  "]},{"cell_type":"markdown","source":["### 1.1. Cargar los datasets a usar\n","\n","El dataset es una adaptación del <a href=http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html> dataset `STOCK`</a>, cogido originalmente del repositorio StatLib. El objetivo de este problema es predecir los valores de las acciones de una empresa aeroespacial determinada, dados los valores de otras 9 empresas en el mismo día.  \n","\n","Puedes explorar los resultados del siguiente notebook usando dos datasets alternativos: \n","\n","\n","* El  <a href=https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength> dataset `CONCRETE` </a> obtenido del <a href=https://archive.ics.uci.edu/ml/index.html> repositorio de Machine Learning en la Universidad de California Irvine</a>. Para ello, simplemente elige `CONCRETE` en la variable ds_name y no `STOCK` en la siguiente celda. Recuerda que debes correr las celdas de nuevo para ver los cambios. El objetivo del dataset `CONCRETE` es predecir la fuerza compresiva de mezclas de cemento basadas en variables observadas relacionadas con la composición de la mezcla y la antigüedad del material. \n","\n","* El dataset `Advertising`, es obtenido del libro <a href=https://www.statlearning.com/> An Introduction to Statistical Learning with applications in R</a> de los autores: G. James, D. Witten, T. Hastie and R. Tibshirani. El objetivo de dicho problema es predecir las ventas de un producto dado, conociendo la inversión en diferentes sectores de publicidad. Más específicamente, las variables de entrada y salida se describen de la siguiente manera:\n","\n","  - *Variables de entrada:*\n","     * TV: dólares de publicidad gastados en TV para un único producto en un mercado determiando (en miles de dólares)\n","     * Radio: dólares de publicidad gastados en Radio\n","     * Newspaper: dólares de publicidad gastados en periódicos\n","     \n","  - *Variable de salida:*\n","     * Sales: ventas de un único producto en un mercado determinado (en miles de widgets)\n","     \n","Puedes echar un vistazo al archivo `Advertising.csv` para tener una idea de la estructura de los datos."],"metadata":{"id":"DCvTI2WoGvuI"}},{"cell_type":"markdown","source":["Empecemos cargando los datos en el espacio de trabajo, y visualizando las dimensiones de todas las matrices."],"metadata":{"id":"f4n4__9MPFu6"}},{"cell_type":"code","source":["# Selecciona el dataset: 'stock', 'concrete' or 'advertising'\n","nombre_dataset = 'stock'\n","\n","if nombre_dataset == 'stock':\n","    # STOCK DATASET\n","    data = scipy.io.loadmat('stock.mat')\n","    X_tr = data['xTrain']\n","    Y_tr = data['sTrain']\n","    X_tst = data['xTest']\n","    Y_tst = data['sTest']\n","\n","elif nombre_dataset == 'concrete':\n","    # CONCRETE DATASET. \n","    data = scipy.io.loadmat('concrete.mat')\n","    X_tr = data['X_tr']\n","    Y_tr = data['S_tr']\n","    X_tst = data['X_tst']\n","    Y_tst = data['S_tst']\n","\n","elif nombre_dataset == 'advertising':    \n","    # ADVERTISING DATASET\n","    df = pd.read_csv('Advertising.csv', header=0)\n","    X_tr = df.values[:150, 1:4]\n","    Y_tr = df.values[:150, -1]\n","    X_tst = df.values[150:, 1:4]\n","    Y_tst = df.values[150:, -1]\n","\n","else:\n","    print('Dataset desconocido')\n","\n","# Muestra las dimensiones de los datos\n","print(X_tr.shape)\n","print(Y_tr.shape)\n","print(X_tst.shape)\n","print(Y_tst.shape)"],"metadata":{"id":"glR5JB70FqKg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"54vO_txYx3sd"},"source":["### 1.2. Visualizar los datos\n","\n","Podemos obtener una severa idea sobre la tarea de regresión representando el *gráfico disperso* de cada variable unidimensional contra la variable objetivo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABWFMGYwx3sd"},"outputs":[],"source":["pylab.subplots_adjust(hspace=0.2)\n","\n","for idx in range(X_tr.shape[1]):\n","    ax1 = plt.subplot(3, 3, idx+1)\n","    ax1.plot(X_tr[:, idx], Y_tr, '.')\n","    ax1.get_xaxis().set_ticks([])\n","    ax1.get_yaxis().set_ticks([])\n","\n","plt.show()"]},{"cell_type":"markdown","source":["> **Ejercicio**: Modifica la celda anterior para añadir los nombres a los ejes, poniendo X0, X1,... según la variable que se está dibujando, y 'Y' para el eje y con la variable objetivo."],"metadata":{"id":"j35bbIsgrN9F"}},{"cell_type":"markdown","metadata":{"id":"CzbgErOLx3se"},"source":["### 1.3. Estimador referencia/*baseline*. Usando la media de la etiquetas del conjunto de entrenamiento\n","\n","Un primer método muy sencillo para construir un modelo de regresión es usar la media de todos los valores objetivo en el conjunto de entrenamiento como la salida, descartando los valores del vector de las observaciones de entrada.\n","\n","Este enfoque se puede considerar como un ***baseline***, dado que cualquier otro método haciendo uso efectivo de las variables de entrada, estadísticamente relacionado con $y$, debería mejorarlo.\n","\n","La predición entonces es dada por\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpPWpwsVx3se"},"outputs":[],"source":["# Media de todas las varibles objetivo en el conjunto de entranmiento\n","y_estimada = np.mean(Y_tr)\n","print(y_estimada)\n","\n","# Creamos las estimaciones del baseline para entrenamiento y test\n","y_estimada_train = np.repeat(y_estimada, Y_tr.shape[0])\n","y_estimada_test = np.repeat(y_estimada, Y_tst.shape[0])"]},{"cell_type":"markdown","metadata":{"id":"XY6H23rax3sf"},"source":["para cualquier entrada ${\\bf x}$."]},{"cell_type":"markdown","metadata":{"id":"SD24KQ0Vx3sf"},"source":[">**Ejercicio**: Calcula el MSE sobre los conjuntos de entrenamiento y test para el método de estimación *baseline*. Para ello utiliza la función de sklearn *mean_squared_error*.\n"]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error"],"metadata":{"id":"Y68JLQge4vAp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_j_Na6Cqx3sg"},"outputs":[],"source":["# MSE del baseline sobre los datos de entrenamiento\n","# MSE_tr = <SOL>\n","\n","# MSE del baseline sobre los datos de test\n","# MSE_tst = <SOL>\n","\n","print('MSE en el conjunto de entrenamiento (baseline): {0}'.format(MSE_tr))\n","print('MSE en el conjunto de test (baseline): {0}'.format(MSE_tst))  "]},{"cell_type":"markdown","metadata":{"id":"i-NSBxPex3sg"},"source":["Ten en cuenta que en la pieza de código anterior, la función 'mean_squared_error' no se puede usar cuando el segundo argumento es un número en vez de un vector con la misma longitud que el primer argumento."]},{"cell_type":"markdown","metadata":{"id":"3x3d5blxx3sh"},"source":["### 1.4. Regresión unidimensional con el método $k$-nn\n","\n","Los principios del método $k$-nn son los siguientes:\n","\n","   - Para cada muestra donde hay que hacer una predicción, encuentra los $k$ vecinos más cercanos a ella (en el conjunto de entrenamiento)\n","   - Obtén una estimación promediando las etiquetas correspondientes a los vecinos seleccionados.\n","\n","El número de vecinos es un hiperparámetro que juega un papel muy importante en el rendimiento del método. \n","\n","> **Ejercicio**: Puedes comprobar su influencia cambiando $k$ en el siguiente código. En particular, puedes empezar con $k=1$ y observar el efecto de aumentar el valor de $k$."]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsRegressor"],"metadata":{"id":"Nty4ANg84w_a"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"kSKWJNkAx3sh"},"outputs":[],"source":["# Código para implementar regresión unidimensional con K-nn\n","# Las estimaciones se hacen solo usando una variable de entrada!!\n","\n","var = 0           # Selecciona la variable (e.g., cualquier valor de 0 a 8 para el dataset STOCK)\n","k = 1             # Número de vecinos\n","n_points = 1000   # Número de puntos en el eje 'x' (con propósito de representación en gráficas)\n","\n","X_tr_var = X_tr[:, var].reshape(-1, 1)      # Siempre que añadimos .reshape(-1, 1) es para convertir de vector de 1D a matriz de 2D, igual que hacía np.newaxis\n","X_tst_var = X_tst[:, var].reshape(-1, 1)\n","\n","# Para la representación, calculamos la salida del modelo en una serie de puntos igualmente distribuidos en el eje x\n","grid_min = np.min([np.min(X_tr_var), np.min(X_tst_var)])    # Valor mínimo del eje a representar y evaluar\n","grid_max = np.max([np.max(X_tr_var), np.max(X_tst_var)])    # Valor máximo del eje a representar y evaluar\n","X_grid = np.linspace(grid_min, grid_max, num=n_points).reshape(-1, 1)            # Crea en eje de puntos\n","\n","# Cargamos el modelo a entrenar con el valor elegido para los hiperparámetros \n","KNN = KNeighborsRegressor(n_neighbors=k)\n","\n","# Entrenamos el modelo\n","KNN.fit(X_tr_var, Y_tr)\n","\n","# Predecimos en los datos de test y en el grid que vamos a evaluar para las representaciones gráficas\n","est_tst = KNN.predict(X_tst_var)\n","est_grid = KNN.predict(X_grid)\n","\n","# Representamos datos de entrenamiento, datos de test y predicciones en todo el eje\n","plt.plot(X_tr_var, Y_tr,'b.', label='Muestras de entrenamiento')\n","plt.plot(X_tst_var, Y_tst,'rx', label='Muestras de test')\n","plt.plot(X_grid, est_grid,'g-', label='Modelo de regresión ')\n","plt.axis('tight')\n","plt.legend(loc='best')"]},{"cell_type":"markdown","metadata":{"id":"CTXS1Rq3x3sh"},"source":["#### 1.4.1. Evolución del error con el número de vecinos ($k$)\n","\n","Podemos ver que un valor pequeño de $k$ resulta en una curva de regresión que presenta muchas oscilaciones grandes. La curva está captando cualquier ruido que pueda estar presente en los datos de entrenamiento y <i>**sobreajusta**</i> el conjunto de entrenamiento. Por otro lado, coger un valor de $k$ muy grande (e.g., 200) hace que la curva de regresión sea muy suave, promediando los valores de las etiquetas en el conjunto de entrenamiento sobre un intervalo muy grande de las variables de observación.\n","\n","El siguiente código ilustra este efecto, dibujando los errores cuadráticos promedio de entrenamiento y test como una función de $k$. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n0JzqdRdx3si"},"outputs":[],"source":["# Puedes jugar a cambiar estos 2 valores\n","var = 0\n","k_max = 60\n","\n","#<SOL>\n","\n","#</SOL>\n","\n","k_max = np.minimum(k_max, X_tr.shape[0])  # k_max no puede ser mayor que el número de muestras\n","\n","# Seleccionamos X de train y de test según la variable escogida\n","X_tr_var = X_tr[:, var].reshape(-1, 1)      # Siempre que añadimos .reshape(-1, 1) es para convertir de vector de 1D a matriz de 2D, igual que hacía np.newaxis\n","X_tst_var = X_tst[:, var].reshape(-1, 1)\n","\n","# Ten cuidado con el uso de range, e.g., range(3) = [0, 1, 2] and range(1, 3) = [1,2]\n","MSEk_tr = [mean_squared_error(Y_tr, KNeighborsRegressor(k).fit(X_tr_var, Y_tr).predict(X_tr_var)) for k in range(1, k_max+1)]\n","MSEk_tst = [mean_squared_error(Y_tst, KNeighborsRegressor(k).fit(X_tr_var, Y_tr).predict(X_tst_var)) for k in range(1, k_max+1)]\n","\n","# Representamos errores de entrenamiento y de test\n","kgrid = np.arange(1, k_max+1)\n","plt.plot(kgrid, MSEk_tr, 'bo', label='MSE entrenamiento')\n","plt.plot(kgrid, MSEk_tst, 'ro', label='MSE test')\n","plt.xlabel('$k$')\n","plt.axis('tight')\n","plt.legend(loc='best')"]},{"cell_type":"markdown","metadata":{"id":"uji2tU59x3si"},"source":["Como podemos ver, el error inicialmente disminuye alcanzando un mínimo, en el conjunto de test, para algún valor finito de $k$ ($k\\approx 10$ para el dataset `STOCK`). Aumentar el valor de $k$ más alla de este número, empobrece el rendimiento del modelo.\n","\n",">**Ejercicio**: Analiza el MSE en entrenamiento para $k=1$. Calcúlalo en la siguiente celda. ¿Por qué es más pequeño que para otros $k$? ¿Bajo qué condiciones será exactamente cero?"]},{"cell_type":"code","source":["#<SOL>\n","\n","#</SOL>"],"metadata":{"id":"7JiyDJ4IjHY1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DyhRfUsPx3si"},"source":[">**Ejercicio**: Modifica el código anterior para ver el MSE desde $k=1$ hasta $k$ igual al número de muestras de entrenamiento. ¿Puedes relacionar el error cuadrático del método $k$-NN con el *baseline* para algún valor de $k$? "]},{"cell_type":"markdown","metadata":{"id":"FF6o_50Bx3sj"},"source":["#### 1.4.2. Influencia de la variable de entrada\n","\n","Echando un ojo a los *scatter plots*, podemos ver que alguna variable de observación parece tener una más clara relación con la variable objetivo. Entonces, podemos esperar que no todas las variables sean igualmente útiles para la tarea de regresión. En la siguiente gráfica estudiamos el rendimiento que puede alcanzar cada variable.\n","\n","Ten en cuenta que, en la práctica, las etiquetas de test no están accesibles para la selección del hiperparámetro $k$, así que debemos tener cuidado sobre las conclusiones de este experimento. Un enfoque más realista se estudiará más adelante con el concepto de validación del modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gyC6nGd_x3sj"},"outputs":[],"source":["k_max = 20\n","\n","performance_variable = []\n","valores_k = []\n","for var in range(X_tr.shape[1]):\n","\n","    X_tr_var = X_tr[:, var].reshape(-1, 1)      # Siempre que añadimos .reshape(-1, 1) es para convertir de vector de 1D a matriz de 2D, igual que hacía np.newaxis\n","    X_tst_var = X_tst[:, var].reshape(-1, 1)\n","\n","    MSE_tr = [mean_squared_error(Y_tr, KNeighborsRegressor(k).fit(X_tr_var, Y_tr).predict(X_tr_var)) for k in range(1, k_max+1)]\n","    MSE_tst = [mean_squared_error(Y_tst, KNeighborsRegressor(k).fit(X_tr_var, Y_tr).predict(X_tst_var)) for k in range(1, k_max+1)]\n","\n","    # Convertimos a array para poder operar con los valores\n","    MSE_tr = np.asarray(MSE_tr)\n","    MSE_tst = np.asarray(MSE_tst)\n","\n","    # Seleccionamos la variable asociada al valor de k para el cual el error es mínimo\n","    pos = np.argmin(MSE_tr)\n","    valores_k.append(pos + 1)\n","    performance_variable.append(MSE_tst[pos])\n","    \n","plt.stem(range(X_tr.shape[1]), performance_variable)\n","plt.title('Resultados de la regresión unidimensional ($k$NN)')\n","plt.xlabel('Variable')\n","plt.ylabel('Test MSE')\n","\n","plt.figure(2)\n","plt.stem(range(X_tr.shape[1]), valores_k)\n","plt.xlabel('Variable')\n","plt.ylabel('$k$')\n","plt.title('Selección de los hiperparámetros')"]},{"cell_type":"markdown","source":["### 1.5. Regresión multidimensional con el método $k$-nn\n","\n","En la sección anterior, hemos estudiado el rendimiento del método $k$-nn cuando sólo usamos una variable. Hacer esto era conveniente, porque nos permitía dibujar las curvas de regresión en una figura de 2D y tener una idea sobre las consecuencias de modificar el número de vecinos.\n","\n","Para completarlo, evaluamos el rendimiento del método $k$-nn en este dataset usando todas las variables juntas. De hecho, cuando diseñas un modelo de regresión, deberías proceder de esta manera, usando toda la información disponible para hacer una estimación lo más precisa posible. De esta forma, podremos también darnos cuenta de posibles correlaciones que pueda haber entre las variables de entrada y que puedan tener información relevante para la tarea de regresión.\n","\n","Por ejemplo, en el dataset `STOCK`, podría ser que la combinación de las acciones de dos empresas de aviones sea más informativa sobre el precio objetivo de la empresa, mientras que el valor de una compañia sólo no es suficiente.\n","\n","\n","También, en el dataset `CONCRETE`, podría ser que para el problema que se trata la combinación de una gran proporción de agua con una pequeña proporción de grano grueso es un claro indicador de cierta fuerza compresiva del material, mientras la proporción de alguna de las dos sustancias por separado no sea sufiecientemente buena para obtener ere resultado.\n","\n","\n"],"metadata":{"id":"QXqwoHpLpFoO"}},{"cell_type":"code","source":["k_max = 20\n","\n","# Ahora cogemos todos los datos y no sólo una variable\n","MSE_tr = [mean_squared_error(Y_tr, KNeighborsRegressor(k).fit(X_tr, Y_tr).predict(X_tr)) for k in range(1, k_max+1)]\n","MSE_tst = [mean_squared_error(Y_tst, KNeighborsRegressor(k).fit(X_tr, Y_tr).predict(X_tst)) for k in range(1, k_max+1)]\n","\n","\n","plt.plot(np.arange(k_max)+1, MSE_tr,'bo',label='Train MSE')\n","plt.plot(np.arange(k_max)+1, MSE_tst,'ro',label='Test MSE')\n","plt.xlabel('k')\n","plt.ylabel('MSE')\n","\n","plt.legend(loc='best')"],"metadata":{"id":"WWLd2w1Yoe93"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En este caso, podemos comprobar que el MSE en test es mucho más bajo que el que se obtenía cuando se usaba una sola variable, y también mucho mejor que el *baseline*. También es interesante ver que en este caso en particular, el mejor resultado se obtiene para un valor pequeño de $k$, con un aumento del error para valores mayores de este.\n","\n","Sin embargo, como se ha mencionado anteriormente, estos resultados se deberían interpretar con cuidado.\n","\n","**Ejercicio**: ¿Cómo seleccionaría el valor de $k$ si las etiquetas de test no están disponibles para la validación del modelo?\n"],"metadata":{"id":"VLF8i5Ju-lB2"}},{"cell_type":"markdown","metadata":{"id":"WOsF3J5hx3sk"},"source":["### 1.6. Selección de los hiperparámeteros via **cross-validation**\n","\n","Un inconveniente de la aplicación del método $k$-nn es que la selección de $k$ influye el error final del algoritmo. En experimentos anteriores, mantenemos el valor de $k$ que minimiza el MSE en el conjunto de entrenamiento. Sin embargo, vimos que la localización del mínimo no es necesariamente la misma desde la perspectiva de los datos de test. Idealmente, nos gustaría que el diseño del modelo de regresión funcione tan bien como sea posible para futuros patrones sin etiquetar que no están disponibles durante la fase de entrenamiento. Esta propiedad se llama <i>generalización</i>. Ajustamos los datos de entrenamiento con la esperanza de indirectamente obtener también un modelo que generalice bien. Para conseguir dicho objetivo, hay estrategias que intentan garantizar una correcta generalización del modelo. Una de dichas estrategias se conoce como validación cruzada o <b>cross-validation</b>, en inglés.\n","\n","Ya que no se permite usar las etiquetas de test durante el entrenamiento (debería dejarse para simular posible aplicaciones futuras del modelo en patrones no observados), necesitamos averiguar una manera de mejorar nuestra estimación de los hiperparámetros que requiera solo datos de entrenamiento.Cross-validation nos permite hacer esto siguiendo una serie de pasos: \n","\n","   - Dividir el conjunto de entrenamiento en diferentes subconjuntos (generalmente no superpuestos). Si usamos $M$ subconjuntos, el método es definido como **$M$-fold cross-validation**. Si consideramos cada muestra como un conjunto diferente, el método es definido como **leave-one-out (LOO) cross-validation**.\n","   - Entrena el sistema $M$ veces. Para cada ejecución, usa diferentes particiones como el conunto de <i>validación</i>, y usa el resto como conjunto de entrenamiento. Evalua el rendimiento para diferentes elecciones del hiperparámetro (i.e., para diferentes valores de $k$ para el método $k$-NN).\n","   - Promedia el error de validación sobre todas las paritciones, y escoge el hiperparámetro que proporcione el mínimo error de validación.\n","   - Vuelve a ejecutar el algoritmo sobre todas las muestras de entrenamiento, manteniendo el valor del hiperparámetro que elegiste del proceso de cross-validation.\n","   \n","<img src=\"https://chrisjmccormick.files.wordpress.com/2013/07/10_fold_cv.png\">"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ykPaUqnzx3sk"},"outputs":[],"source":["### Este fragmento de código ejecuta k-nn con validación cruzada M-fold \n","\n","# Parámetros:\n","M = 5       # Número de subconjuntos para M-cv\n","k_max = 40  # Máximo valor del parámetro k del knn que se va a explorar\n","\n","# Primero calculamos la curva del error de entrenamiento, que va a ser útil para comparación visual\n","MSE_tr = [mean_squared_error(Y_tr, KNeighborsRegressor(k).fit(X_tr, Y_tr).predict(X_tr)) for k in range(1, k_max+1)]\n","\n","## M-CV\n","# Obtenemos los índices de las observaciones para los diferentes subconjuntos\n","n_tr = X_tr.shape[0]\n","permutacion = np.random.permutation(n_tr)\n","\n","# Dividimos los índices en M subconjuntos de (casi) el mismo tamaño. \n","conjuntos_indices = {i: [] for i in range(M)}\n","i = 0\n","for pos in range(n_tr):\n","    conjuntos_indices[i].append(permutacion[pos])\n","    i = (i+1) % M\n","    \n","# Obtenemos los errores de validacion\n","MSE_val = np.zeros((1,k_max))\n","for i in range(M):\n","    val_indices = conjuntos_indices[i]\n","    \n","    # Sacamos los val_indices del conjunto de índices.\n","    tr_indices = list(set(permutacion) - set(val_indices))\n","    \n","    MSE_val_iter = [mean_squared_error(Y_tr[val_indices], KNeighborsRegressor(k).fit(X_tr[tr_indices, :], Y_tr[tr_indices]).predict(X_tr[val_indices, :])) for k in range(1, k_max+1)]\n","\n","    MSE_val = MSE_val + np.asarray(MSE_val_iter).T\n","    \n","MSE_val = MSE_val/M\n","\n","# Selecciona el mejor k basado en el error de validación\n","k_mejor = np.argmin(MSE_val) + 1\n","\n","# Calcula el MSE de test final para el k seleccionado\n","MSE_tst = mean_squared_error(Y_tst, KNeighborsRegressor(k_mejor).fit(X_tr, Y_tr).predict(X_tst))\n","\n","plt.plot(np.arange(k_max)+1, MSE_tr, 'bo', label='Entrenamiento MSE')\n","plt.plot(np.arange(k_max)+1, MSE_val.T, 'go', label='Validación MSE')\n","plt.plot([k_mejor, k_mejor], [0, MSE_tst],'r-')\n","plt.plot(k_mejor, MSE_tst,'ro',label='Test MSE')\n","plt.legend(loc='best')\n","plt.xlabel('k')\n","plt.ylabel('MSE')"]},{"cell_type":"markdown","source":["Para los próximos notebooks usaremos la librería de Sklearn también para hacer validación cruzada, por lo que puedes ignorar el código anterior. Se ha usado simplemente con méritos de entender cómo funciona esta estragia."],"metadata":{"id":"hpbwMvC10q_N"}},{"cell_type":"markdown","metadata":{"id":"KOdNNxIRx3sl"},"source":["> **Ejercicio EXTRA!**: Modifica el código anterior para usar sólo una de las variables de entrada en el dataset.\n","  - Siguiendo un enfoque de validación cruzada, selecciona el mejor valor de $k$ para el $k$-nn basado solo en la variable 0.\n","  - Calcula el error de test para el valor seleccionado de $k$."]},{"cell_type":"code","source":["#<SOL>\n","\n","#</SOL>"],"metadata":{"id":"zcSKBiwOEIAZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MNTRP89rx3sl"},"source":["## 2. Ahora tú! Ejemplo de implementación del KNN en Scikit-learn\n","\n","En la práctica, los modelos más conocidos de ML están implementados y disponibles para python. Probablemente, uno de los módulos/librerías más completos para herramientas de ML es <a href=http://scikit-learn.org/stable/>Scikit-learn</a>. En la siguiente pieza de código debes utilizar el método\n","\n","    KNeighborsRegressor\n","   \n","disponible en Scikit-learn, como se ha hecho anteriormente en el notebook. A continuación mostramos un ejemplo que se ha tomado de <a href=http://scikit-learn.org/stable/auto_examples/neighbors/plot_regression.html>aquí</a>. Como puedes comprobar, esta rutina permite construir la estimación de una muestra en particular usando la media ponderada de los vecinos objetivo: \n","\n","   Para obtener la estimación de una muestra ${\\bf x}$:\n","   \n","   - Encuentra las $k$ muestras más cercanas a ${\\bf x}$ en el conjunto de entrenamiento.\n","   - Promedia las correspondientes muestras objetivo, ponderando cada valor de acuerdo a la distancia de cada muestra a ${\\bf x}$, de manera que las muestras más cercanas tienen mayor influencia en la estimación.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ONCBV2lgx3sl"},"outputs":[],"source":["# Generamos las observaciones de los datos\n","np.random.seed(0)\n","X = np.sort(5 * np.random.rand(40, 1), axis=0)\n","T = np.linspace(0, 5, 500)[:, np.newaxis]\n","y = np.sin(X).ravel()\n","\n","# Añadimos ruido al 'target'\n","y[::5] += 1 * (0.5 - np.random.rand(8))\n","\n","\n","# Ajustamos el modelo de regresión\n","n_neighbors = 5\n","\n","for i, weights in enumerate([\"uniform\", \"distance\"]):\n","    # Creamos el modelo\n","    knn = KNeighborsRegressor(n_neighbors, weights=weights)\n","    # Entrenamos el modelo y predecimos las salidas de los datos\n","    knn.fit(X, y)\n","    y_ = knn.predict(T)\n","\n","    plt.subplot(2, 1, i + 1)\n","    plt.scatter(X, y, color=\"darkorange\", label=\"data\")\n","    plt.plot(T, y_, color=\"navy\", label=\"prediction\")\n","    plt.axis(\"tight\")\n","    plt.legend()\n","    plt.title(\"KNeighborsRegressor (k = %i, weights = '%s')\" % (n_neighbors, weights))\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","source":["> **Ejercicio**: Investiga qué significa el parámetro __weights__ que usa el código anterior. O, intuyelo a través de la gráfica obtenida."],"metadata":{"id":"J9cuErnV1-2H"}},{"cell_type":"markdown","metadata":{"id":"QzRzrg7wx3sl"},"source":["> **Ejercicio**: Utiliza la implementación de scikit-learn para el método $k$-nn para calcular las predicciones en el dataset `CONCRETE`. Compara el resultado cuando usas pesos uniformes con respecto a los basados en distancia en el cálculo de las predicciones. Visualiza las curvas del error cuadrático medio (MSE) para diferentes valores de $k$."]},{"cell_type":"code","source":["#<SOL>\n","\n","#</SOL>"],"metadata":{"id":"pLD8JaBrHjgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#<SOL>\n","\n","#</SOL>"],"metadata":{"id":"Aspqrmbe2ubl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> **Ejercicio EXTRA!**: Prueba a entrenar un Regresor lineal o no lineal a los mismos datos y compara los resultados con el KNN. ¿Qué módelo es mejor? \n","\n","Ten en cuenta que no podemos hacer conclusiones reales porque el conjunto de test no se puede usar para elegir ningún hiperparámetro como la k. Más adelante veremos la implementación de la validación cruzada para solventar este problema. Puedes probar el primer notebook extra de regresión para ello."],"metadata":{"id":"hVB3LeCZC7ps"}},{"cell_type":"code","source":["#<SOL>\n","\n","#</SOL>"],"metadata":{"id":"iM5XHSX2C7-0"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMlXsJ96VJPLHxYGlqQ4j2f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Modelos de Clasificación\n","\n","------------------------------------------------------\n","\n","\n","### Data Science and Machine Learning\n","\n","#### Marzo 2023\n","\n","**Aurora Cobo Aguilera**\n","\n","**The Valley**\n","\n","------------------------------------------------------"],"metadata":{"id":"rAisAI1Mqjue"}},{"cell_type":"markdown","metadata":{"id":"dq7x3jK5NuHD"},"source":["<a id='multiclase'></a>\n","# 1. Clasificación multi-clase con clasificadores binarios\n","---\n","\n","Hasta ahora hemos trabajado con problemas de clasificación binaria, en los que la etiqueta por dato únicamente toma dos valores ($Y=0$, $Y=1$). Una forma de abordar problemas de clasificación multiclase $Y\\in\\{0,1, \\ldots, M-1\\}$ es transformar el problema en múltiples clasificadores binarios.\n","\n","Hay dos estrategias fundamentales: 1 contra 1 y uno contra todos."]},{"cell_type":"markdown","metadata":{"id":"2WfWBt7wNuHD"},"source":["### Clasificación multi-clase 1 contra 1\n","\n","- Esta estrategia consiste en ajustar un clasificador por cada par de clases. \n","- En el momento de la predicción cada observación de test se clasifica con todos los clasificadores binarios, y cada clasificador asigna esa observación a una de sus dos posibles clases: vota por una clase. La clase final a la que se asigna la observación de test es aquella que recibió más votos\n","- Hay que ajustar M * (M - 1) / 2 clasificadores binarios.\n","- Cada uno de ellos sólo involucra un conjunto pequeño de datos (los correspondientes a ambas clases).\n","- En caso de empate hay que decidir una estrategia.\n","\n","### Clasificación uno contra todos\n","\n","- Se ajusta un clasificador por clase (M en total), que clasifica entre dicha clase o cualquiera de las demás.\n","- Mayor interpretabilidad (cada clase sólo participa en un clasificador).\n","- En predicción, se selecciona la clase con mayor confianza. Por ejemplo, mayor probabilidad en el regresor logístico.\n","- Un empate es en general improbable (no comparamos votos sino confianza en la predicción).\n"," \n"," <img src='http://www.tsc.uc3m.es/~olmos/BBVA/multi_labelv2.jpeg' width=800/>\n","\n","\n","Para implementar estas estrategias, utilizaremos las funciones [OneVsOneClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier) y [OneVsRestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier) de sklearn. Ambas clases se utilizan de forma muy parecida.\n","\n","Vamos a utilizar de nuevo un data set en 2 dimensiones para visualizar las dos estrategias de clasificación multiclase."]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier"],"metadata":{"id":"PnC8hxMrnGdY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhU5By-PNuHD"},"outputs":[],"source":["# Cargamos dataset\n","\n","data_ejemplo3 = pd.read_csv('http://www.tsc.uc3m.es/~olmos/BBVA/ejemplo3.txt',header=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WawOu0hWNuHF"},"outputs":[],"source":["data = np.array(data_ejemplo3)\n","\n","## Separamos X e Y\n","X03=data[:,0:2]\n","Y3=data[:,2]\n","\n","# Separamos train de test\n","X03_train, X03_test, Y3_train, Y3_test = train_test_split(X03, Y3, test_size=0.2, random_state=0)\n","\n","print(\"El conjunto de datos de entrenamiento consta {0:d} observaciones de {1:d} dimensiones\\n\".format(X03_train.shape[0], X03_train.shape[1]))\n","\n","# Variables para la representación de la frontera de decisión (antes de normalizar!)\n","min1=np.min(X03_train[:,0])\n","max1=np.max(X03_train[:,0])\n","min2=np.min(X03_train[:,1])\n","max2=np.max(X03_train[:,1])\n","\n","# Normalización\n","\n","transformer3 = StandardScaler().fit(X03_train)\n","\n","X3_train = transformer3.transform(X03_train)\n","X3_test = transformer3.transform(X03_test)"]},{"cell_type":"markdown","metadata":{"id":"KDJ400czNuHF"},"source":["Vamos a dibujar el histograma de las clases en el conjunto de training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXDUIDt9NuHG"},"outputs":[],"source":["classes,unique_counts = np.unique(ar=Y3_train,return_counts=True)"]},{"cell_type":"code","source":["def muestra_frontera(X_train,Y_train,x1_grid=None,x2_grid=None,probs_grid=None,dataset=False,frontera=False,thresholds=[0.5],\n","                     prob_levels=False, titulo='Datos',xlabel='$x_1$',ylabel='$x_2$'):\n","    \n","    \"\"\"\n","    - dataset=True --> Representamos solo el dataset\n","    - frontera=True --> Representamos dataset con frontera de decisión (podemos especificar mas niveles con thresholds)\n","    - prob_levels=True --> Representamos dataset con curvas de nivel de probabilidad de clase 1.\n","    \"\"\"\n","    \n","    # Identificamos clases\n","    clases = np.unique(Y_train).astype(np.int32)\n","    labels = ['Class ' + str(int(c)) for c in clases]\n","    \n","    if(dataset==True):\n","        \n","        # Dibujamos únicamente dataset\n","        plt.figure()\n","        for c in clases:\n","            plt.plot(X_train[Y_train==c,0],X_train[Y_train==c,1],'s',label=labels[c])\n","        plt.xlabel(xlabel)\n","        plt.ylabel(ylabel)\n","        plt.legend(loc='upper right')\n","        plt.title(titulo)\n","        plt.grid(visible=True, which='major', color='gray', alpha=0.6, linestyle='dotted', lw=1.5)\n","        plt.show()\n","    \n","    if(frontera==True):\n","        \n","        # Dibujamos dataset + líneas de contorno definidas en `thresholds`\n","        fig,ax = plt.subplots()\n","        for c in clases:\n","            plt.plot(X_train[Y_train==c,0],X_train[Y_train==c,1],'s',label=labels[c])\n","        cs=ax.contour(x1_grid,x2_grid,np.reshape(probs_grid[:,1],np.shape(x1)),thresholds,linestyles='dashed')\n","        ax.clabel(cs, inline=1, fontsize=12)\n","        plt.xlabel(xlabel)\n","        plt.ylabel(ylabel)\n","        plt.legend(loc='upper right')\n","        plt.title(titulo)\n","        plt.grid(visible=True, which='major', color='gray', alpha=0.6, linestyle='dotted', lw=1.5)\n","        plt.show()\n","\n","    if(prob_levels==True):\n","        \n","        # Dibujamos dataset + mapa de probabilidades\n","        fig,ax = plt.subplots()\n","        for c in clases:\n","            plt.plot(X_train[Y_train==c,0],X_train[Y_train==c,1],'s',label=labels[c])\n","        cs = ax.contourf(x1_grid,x2_grid,np.reshape(probs_grid[:,1],np.shape(x1)),np.arange(0,1.1,0.0005),linestyles='dashed',cmap='Greys')\n","        cbar = fig.colorbar(cs)\n","        plt.xlabel(xlabel)\n","        plt.ylabel(ylabel)\n","        plt.legend(loc='upper right')\n","        plt.title(titulo)\n","        plt.grid(visible=True, which='major', color='gray', alpha=0.6, linestyle='dotted', lw=1.5)\n","        plt.show()\n","    "],"metadata":{"id":"3iKQ0YS0ojxo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5nCF0EdNuHH"},"outputs":[],"source":["labels = [r'Class ' + str(int(c)) for c in classes]\n","width = 0.35  # Anchura de las barras\n","\n","fig, ax = plt.subplots()\n","rect = ax.bar(classes, unique_counts, width=width)\n","plt.grid(visible=True, which='major', color='gray', alpha=0.6, linestyle='dotted', lw=1.5)\n","plt.xticks(classes,labels)\n","plt.show()\n","\n","# Representaciones usando la función muestra_frontera\n","muestra_frontera(X_train=X03_train,Y_train=Y3_train,dataset=True,titulo='Dataset Multiclase')"]},{"cell_type":"markdown","metadata":{"id":"vzpi0Q5qNuHI"},"source":["Claramente es un dataset complicado! Vamos a ilustrar la clasificación multiclase usando un modelo no-paramétrico,  k-NN.\n","\n","### 1.1. Implementación 1 contra 1 con k-nn\n","\n","Cada uno de los 3 clasificadores k-NN tendrá un valor de k en general distinto, que vamos a validar usando `GridSearchCV`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jucBV1ZBNuHJ"},"outputs":[],"source":["from sklearn.multiclass import OneVsOneClassifier\n","\n","# Parámetros\n","K_max = 20\n","rango_K = np.arange(1, K_max+1)\n","nfold = 10\n","# Define un diccionario con el nombre de los parámetros a explorar como clave y los rangos como valor \n","diccionario_parametros = [{'n_neighbors': rango_K}]\n","\n","# Validación cruzada con GridSearchCV\n","mi_knn3 = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=diccionario_parametros, cv=nfold)\n","\n","mi_knn3_OneVsOne = OneVsOneClassifier(mi_knn3).fit(X3_train,Y3_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ON9xkOJLNuHK"},"outputs":[],"source":["# Podemos ver la lista de clasificadores entrenados\n","print(mi_knn3_OneVsOne.estimators_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c8ocw_IPNuHL"},"outputs":[],"source":["# Y el número de vecinos validado para cada uno de ellos\n","for i, clasificador in enumerate(mi_knn3_OneVsOne.estimators_):\n","    print(\"El número de vecinos para el clasificador {0:d} es {1:d}\".format(i,clasificador.best_params_['n_neighbors']))"]},{"cell_type":"markdown","metadata":{"id":"2k6fmaB8NuHN"},"source":["Imprimamos la región de decisión para cada uno de los 3 clasificadores ..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BeOLZbWFNuHN"},"outputs":[],"source":["#Obtenemos una rejilla de puntos en los que evaluaremos nuestro RL (espacio original de los datos!)\n","x1,x2 = np.mgrid[min1:max1:(max1-min1)/50, min2:max2:(max2-min2)/50]\n","grid = np.transpose(np.row_stack([x1.ravel(), x2.ravel()]))\n","\n","# Normalizamos la rejilla\n","grid_norm = transformer3.transform(grid)\n","\n","for i,c in enumerate(mi_knn3_OneVsOne.estimators_):\n","    \n","    #Estimamos la probabilidad asociada a cada punto con el método .predic_proba\n","    probs_KNN3=c.predict_proba(grid_norm)\n","    \n","    label = 'k-NN One Vs One. Clasificador ' + str(i)\n","\n","    # Representaciones usando la función muestra_frontera\n","    muestra_frontera(x1_grid=x1,x2_grid=x2,probs_grid=probs_KNN3,\n","                     X_train=X03_train,Y_train=Y3_train,frontera=True,\n","                     titulo=label)\n"]},{"cell_type":"markdown","metadata":{"id":"yGwUpguZNuHO"},"source":["A la vista de los diagramas, podemos comprobar que\n","- El primer clasificador separa la clase 0 de la 1\n","- El segundo clasificador separa la clase 0 de la 2\n","- El tercer clasificador separa la clase 1 de la 2\n","\n","Finalmente, para comprobar cómo de bien funciona el k-NN multi-clase que hemos implementado, vamos a obtener la **matriz de confusión**. Sklearn proporciona una clase  que permite dibujar la matrix de confusión de forma muy clara.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aARRqGrNNuHP"},"outputs":[],"source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","ConfusionMatrixDisplay.from_estimator(mi_knn3_OneVsOne, X3_test, Y3_test)"]},{"cell_type":"markdown","metadata":{"id":"mY3zA5xbNuHS"},"source":["Como podemos comprobar la tasa de error de clasificador es muy baja! Solo hay 5 puntos fuera de la diagonal en la matriz de confusión."]},{"cell_type":"markdown","metadata":{"id":"EhJkgT1XNuHT"},"source":["\n","\n","### 1.2. Implementación 1 contra todos con k-nn\n","\n","Cada uno de los 3 clasificador k-NN tendrá un valor de k en general distinto, que vamos a validar usando `GridSearchCV`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WGtRthlNNuHT"},"outputs":[],"source":["from sklearn.multiclass import OneVsRestClassifier\n","\n","mi_knn3_OneVsRest = OneVsRestClassifier(mi_knn3).fit(X3_train,Y3_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M852Aw1CNuHU"},"outputs":[],"source":["# Y el número de vecinos validado para cada uno de ellos\n","for i,clasificador in enumerate(mi_knn3_OneVsRest.estimators_):\n","    print(\"El número de vecinos para el clasificador {0:d} es {1:d}\".format(i,clasificador.best_params_['n_neighbors']))"]},{"cell_type":"markdown","metadata":{"id":"KHOZw7mwNuHW"},"source":["Imprimamos la región de decisión para cada uno de los 3 clasificadores ..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-YMPjSpNuHW"},"outputs":[],"source":["#Obtenemos una rejilla de puntos en los que evaluaremos nuestro RL (espacio original de los datos!)\n","x1,x2 = np.mgrid[min1:max1:(max1-min1)/50, min2:max2:(max2-min2)/50]\n","grid = np.transpose(np.row_stack([x1.ravel(), x2.ravel()]))\n","\n","# Normalizamos la rejilla\n","grid_norm = transformer3.transform(grid)\n","\n","for i,c in enumerate(mi_knn3_OneVsRest.estimators_):\n","    \n","    #Estimamos la probabilidad asociada a cada punto con el método .predic_proba\n","    probs_KNN3=c.predict_proba(grid_norm)\n","    \n","    label = r'k-NN One Vs Rest. Clasificador ' + str(i)\n","\n","    # Representaciones usando la función muestra_frontera\n","    muestra_frontera(x1_grid=x1,x2_grid=x2,probs_grid=probs_KNN3,\n","                     X_train=X03_train,Y_train=Y3_train,frontera=True,\n","                     titulo=label)\n"]},{"cell_type":"markdown","metadata":{"id":"5tqOo2_cNuHX"},"source":["A la vista de los diagramas, podemos comprobar que\n","- El primer clasificador separa la clase 0 del resto\n","- El segundo clasificador separa la clase 1 del resto\n","- El tercer clasificador separa la clase 2 del resto\n","\n","Finalmente, para comprobar cómo de bien funciona el k-NN multi-clase que hemos implementado, vamos a obtener la matriz de confusión:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IrwnIY11NuHY","scrolled":false},"outputs":[],"source":["ConfusionMatrixDisplay.from_estimator(mi_knn3_OneVsRest, X3_test, Y3_test)"]},{"cell_type":"markdown","source":[" > **Ejercicio**: Utilizando Regresión Logística (RL), expansión polinómica hasta grado 5 y regularización L2, muestre las regiones de decisión de los tres clasificadores entrenados en un esquema OneVsRest."],"metadata":{"id":"vR-pacPAqpnL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"84ef6hzKMd3i"},"outputs":[],"source":["# Primero incluimos las variables polinómicas\n","\n","poly_grado5= PolynomialFeatures(5,include_bias=False) #No usamos x^0 = 1\n","\n","X03_train_grado5 =  #<SOL>\n","\n","X03_test_grado5 = #<SOL>\n","\n","# Normalización\n","\n","transformer3_grado5 = StandardScaler().fit(X03_train_grado5)\n","\n","X3_train_grado5 =  #<SOL>\n","X3_test_grado5 =  #<SOL>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o7ZZVMO3Md3i"},"outputs":[],"source":["# Entrenamiento RL con validación parámetro de regularización L2\n","rango_C = np.logspace(-2, 1, 20)  # Rango C en escala logarítmica (base 10). Esto es, 20 puntos desde 10^-2, a 10^1.\n","diccionario_parametros =  #<SOL>\n","nfold = 10 # Número de particiones train/validación\n","\n","RL3 = GridSearchCV#<SOL>\n","\n","RL3_OneVsRest =  #<SOL>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pD2g4OlIMd3i"},"outputs":[],"source":["# Y el hiperparámetro C validado para cada uno de ellos\n","for i,clasificador in enumerate(RL3_OneVsRest.estimators_):\n","    print(\"El hiperparámetro C para el clasificador {0:d} es {1:f}\".format(i,clasificador.best_params_['C']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEeQmhsBMd3i"},"outputs":[],"source":["# Obtenemos una rejilla de puntos en los que evaluaremos nuestro RL (espacio original de los datos!)\n","x1,x2 = np.mgrid[min1:max1:(max1-min1)/50, min2:max2:(max2-min2)/50]\n","grid = np.transpose(np.row_stack([x1.ravel(), x2.ravel()]))\n","\n","# Obtenemos una rejilla de puntos en los que evaluaremos nuestro RL (espacio original de los datos!)\n","grid_ext = poly_grado5.transform(grid)\n","\n","# Normalizamos la rejilla\n","grid_norm =   #<SOL> \n","\n","for i,c in enumerate(RL3_OneVsRest.estimators_):\n","    \n","    # Estimamos la probabilidad asociada a cada punto con el método .predic_proba\n","    probs_RL3=   #<SOL>\n","    \n","    label = r'k-NN One Vs Rest. Clasificador ' + str(i)\n","\n","    # Representaciones usando la función muestra_frontera\n","    muestra_frontera(x1_grid=x1,x2_grid=x2,probs_grid=probs_RL3,\n","                     X_train=X03_train,Y_train=Y3_train,frontera=True,\n","                     titulo=label)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZbpqmruMd3i"},"outputs":[],"source":["# Finalmente mostramos matriz de confusión\n","ConfusionMatrixDisplay.from_estimator(RL3_OneVsRest, X3_test_grado5, Y3_test)"]}]}